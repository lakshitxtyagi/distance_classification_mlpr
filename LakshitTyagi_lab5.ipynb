{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "###### Follow the instructions given in comments prefixed with ## and write your code below that.\n",
    "###### Also fill the partial code in given blanks. \n",
    "###### Don't make any changes to the rest part of the codes\n",
    "\n",
    "### Answer the questions given at the end of this notebook within your report.\n",
    "\n",
    "\n",
    "### You would need to submit your GitHub repository link. Refer to the Section 6: Final Submission on the PDF document for the details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# Read the image plaksha_Faculty.jpg\n",
    "img = cv2.imread(\"Plaksha_Faculty.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load Haar cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Detect faces in the image\n",
    "faces_rect = face_cascade.detectMultiScale(gray_img, 1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
    "\n",
    "# Define text parameters\n",
    "text = \"Face\"\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "font_color = (0, 0, 255)  # Red color in BGR\n",
    "font_thickness = 1\n",
    "\n",
    "# Draw rectangles around faces and add labels\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    cv2.putText(img, text, (x, y-5), font, font_scale, font_color, font_thickness)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(f\"Total number of faces detected: {len(faces_rect)}\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert image to HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hue_saturation = []\n",
    "face_images = []\n",
    "\n",
    "# Extract Hue and Saturation values\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    face = img_hsv[y:y + h, x:x + w]\n",
    "    hue = np.mean(face[:, :, 0])\n",
    "    saturation = np.mean(face[:, :, 1])\n",
    "    hue_saturation.append((hue, saturation))\n",
    "    face_images.append(face)\n",
    "\n",
    "hue_saturation = np.array(hue_saturation)\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(hue_saturation)\n",
    "\n",
    "# Create a figure\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot clustered faces\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.scatter(hue_saturation[i, 0], hue_saturation[i, 1], c='r' if kmeans.labels_[i] == 0 else 'b')\n",
    "\n",
    "plt.xlabel(\"Hue\")\n",
    "plt.ylabel(\"Saturation\")\n",
    "plt.title(\"Face Clustering based on Hue and Saturation\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for clusters\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "cluster_0_points = np.array([hue_saturation[i] for i in range(len(kmeans.labels_)) if kmeans.labels_[i] == 0])\n",
    "cluster_1_points = np.array([hue_saturation[i] for i in range(len(kmeans.labels_)) if kmeans.labels_[i] == 1])\n",
    "\n",
    "plt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], c='green', label=\"Cluster 0\")\n",
    "plt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], c='blue', label=\"Cluster 1\")\n",
    "\n",
    "# Compute and plot centroids\n",
    "centroid_0 = kmeans.cluster_centers_[0]\n",
    "centroid_1 = kmeans.cluster_centers_[1]\n",
    "plt.scatter(centroid_0[0], centroid_0[1], c='black', marker='x', s=100, label=\"Centroid 0\")\n",
    "plt.scatter(centroid_1[0], centroid_1[1], c='black', marker='x', s=100, label=\"Centroid 1\")\n",
    "\n",
    "plt.xlabel(\"Hue\")\n",
    "plt.ylabel(\"Saturation\")\n",
    "plt.title(\"K-Means Clustering of Faces\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Template Matching\n",
    "template_img = cv2.imread(\"Dr_Shashi_Tharoor.jpg\")\n",
    "template_gray = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect face in template image\n",
    "template_faces = face_cascade.detectMultiScale(template_gray, 1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
    "\n",
    "# Draw rectangles around detected faces\n",
    "for (x, y, w, h) in template_faces:\n",
    "    cv2.rectangle(template_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow(\"Template Image - Detected Face\", template_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "## Answer the following questions within your report:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the common distance metrics used in distance-based classification algorithms? \n",
    "\n",
    "The most common distance measures employed in distance-based classification techniques are:\n",
    "\n",
    "Euclidean Distance: Calculates the straight-line distance between two points in a multi-dimensional space.\n",
    "\n",
    "Mahalanobis Distance: Takes into account correlations between variables and scales data, commonly applied in anomaly detection.\n",
    "\n",
    "Manhattan Distance: Calculates the sum of absolute differences between coordinates (also referred to as taxicab or city block distance).\n",
    "\n",
    "Minkowski Distance: Generalization of both Euclidean and Manhattan distances.\n",
    "\n",
    "Cosine Similarity: Calculates the cosine of the angle between two vectors, applied in text classification and high-dimensional space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are some real-world applications of distance-based classification algorithms? \n",
    "\n",
    "Distance-based classification algorithms, i.e., K-Nearest Neighbors (KNN), are applied in the following applications:\n",
    "\n",
    "Handwritten Digit Recognition: Applied in Optical Character Recognition (OCR) systems.\n",
    "\n",
    "Medical Diagnosis: Assists in the classification of diseases according to patient symptoms.\n",
    "\n",
    "Recommender Systems: Recommends products based on user interests by calculating similarity.\n",
    "\n",
    "Anomaly Detection: Finds out fraudulent financial transactions.\n",
    "\n",
    "Face Recognition: Compares face embeddings in security and surveillance systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain various distance metrics. \n",
    "\n",
    "Euclidean Distance: That measures the straight-line distance between two points in space and is commonly utilized in classification and clustering.\n",
    "\n",
    "Mahalanobis Distance: Takes into consideration correlations in data and scales features proportionally, thus being effective for anomaly detection and high-dimensional data.\n",
    "\n",
    "Manhattan Distance: Calculates the total of absolute differences in coordinates, similar to movement in a grid-like direction.\n",
    "\n",
    "Minkowski Distance: An extension of Manhattan and Euclidean distances, where the contribution of varying dimensions is governed by a parameter.\n",
    "\n",
    "Cosine Similarity: Compares the angle between two vectors to compute similarity, generally applied in document and text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the role of cross validation in model performance? \n",
    "\n",
    "Cross-validation assists in the evaluation of the model's performance by:\n",
    "\n",
    "Avoiding overfitting through the assurance of the model generalizing well to unseen data.\n",
    "\n",
    "Giving a more accurate estimate of accuracy by averaging over multiple splits.\n",
    "\n",
    "Assisting in hyperparameter tuning by comparing different settings (e.g., best k value in K-NN).\n",
    "\n",
    "Some common approaches are k-fold cross-validation, leave-one-out cross-validation (LOOCV), and stratified k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Explain variance and bias in terms of KNN? \n",
    "\n",
    "Bias: How far the model's predictions are from the true values. A high bias model (e.g., large k in K-NN) simplifies patterns too much, resulting in underfitting.\n",
    "\n",
    "Variance: How much the model's predictions vary with different datasets. A high variance model (e.g., small k in K-NN) memorizes training data, resulting in overfitting.\n",
    "\n",
    "Bias-Variance Tradeoff: Low k (e.g., 1-NN) → Low bias, high variance (overfits).\n",
    "High k → High bias, low variance (underfits).\n",
    "Optimal k trades off bias and variance for improved generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
